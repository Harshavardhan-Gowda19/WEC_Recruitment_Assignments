{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWFv68UmrMiR",
        "outputId": "4863dd8d-5890-43ea-9a11-f9f0b3ade1c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/archive.zip\" /content/"
      ],
      "metadata": {
        "id": "m_cv7JxHrX_h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/archive.zip\" -d /content/"
      ],
      "metadata": {
        "id": "O8oN26RYrcZ1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Data Preparation"
      ],
      "metadata": {
        "id": "45ebXacZQbfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data Preparation\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Function to load images from a directory\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, (224, 224))\n",
        "            img = img / 255.0  # Normalize to [0, 1]\n",
        "            images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load raw and reference images\n",
        "raw_images = load_images_from_folder('/content/Train/Raw')\n",
        "reference_images = load_images_from_folder('/content/Train/Reference')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test = train_test_split(raw_images, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "mluI0QkZRAF8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Define the VAE Architecture"
      ],
      "metadata": {
        "id": "EFmnvPnGRI25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define the VAE Architecture\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Encoder\n",
        "latent_dim = 64  # Latent space dimension\n",
        "\n",
        "encoder_input = layers.Input(shape=(224, 224, 3))\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoder_input)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# Flatten the output\n",
        "x = layers.Flatten()(x)\n",
        "# Mean and log variance\n",
        "z_mean = layers.Dense(latent_dim)(x)\n",
        "z_log_var = layers.Dense(latent_dim)(x)\n",
        "\n",
        "# Reparameterization Trick\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = tf.keras.backend.random_normal(shape=tf.shape(z_mean))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "# Latent space\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
        "\n",
        "# Decoder\n",
        "decoder_input = layers.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(28 * 28 * 128, activation='relu')(decoder_input)\n",
        "x = layers.Reshape((28, 28, 128))(x)\n",
        "x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoder_output = layers.Conv2DTranspose(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Build VAE model\n",
        "encoder = models.Model(encoder_input, [z_mean, z_log_var, z], name='encoder')\n",
        "decoder = models.Model(decoder_input, decoder_output, name='decoder')\n",
        "vae_output = decoder(encoder(encoder_input)[2])\n",
        "\n",
        "# VAE Model\n",
        "vae = models.Model(encoder_input, vae_output, name='vae')\n"
      ],
      "metadata": {
        "id": "9-TTM6tQRLIt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Define Loss Function"
      ],
      "metadata": {
        "id": "EMWuPz-pRTjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Define Loss Function\n",
        "class VAEModel(tf.keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAEModel, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        reconstructed = self.decoder(z)\n",
        "        kl_loss = -0.5 * tf.reduce_mean(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
        "        self.add_loss(kl_loss)  # Add KL loss to the model's losses\n",
        "        return reconstructed\n",
        "\n",
        "vae_model = VAEModel(encoder, decoder)\n",
        "\n",
        "# Compile the model\n",
        "vae_model.compile(optimizer='adam', loss='mean_squared_error')\n"
      ],
      "metadata": {
        "id": "_Uxwh1R8RW0-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Training the VAE"
      ],
      "metadata": {
        "id": "vhEorVQERZo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Training the VAE\n",
        "history = vae_model.fit(X_train, X_train,\n",
        "                         epochs=200,\n",
        "                         batch_size=16,\n",
        "                         validation_data=(X_test, X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjBt8pPERcxE",
        "outputId": "694ccdb6-b386-4f94-cea1-b61232cdadd4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "35/35 [==============================] - 22s 566ms/step - loss: 0.0617 - val_loss: 0.0464\n",
            "Epoch 2/200\n",
            "35/35 [==============================] - 19s 533ms/step - loss: 0.0451 - val_loss: 0.0472\n",
            "Epoch 3/200\n",
            "35/35 [==============================] - 19s 533ms/step - loss: 0.0449 - val_loss: 0.0444\n",
            "Epoch 4/200\n",
            "35/35 [==============================] - 18s 528ms/step - loss: 0.0429 - val_loss: 0.0438\n",
            "Epoch 5/200\n",
            "35/35 [==============================] - 18s 522ms/step - loss: 0.0432 - val_loss: 0.0450\n",
            "Epoch 6/200\n",
            "35/35 [==============================] - 18s 526ms/step - loss: 0.0431 - val_loss: 0.0438\n",
            "Epoch 7/200\n",
            "35/35 [==============================] - 18s 528ms/step - loss: 0.0424 - val_loss: 0.0430\n",
            "Epoch 8/200\n",
            "35/35 [==============================] - 19s 542ms/step - loss: 0.0425 - val_loss: 0.0444\n",
            "Epoch 9/200\n",
            "35/35 [==============================] - 18s 511ms/step - loss: 0.0426 - val_loss: 0.0434\n",
            "Epoch 10/200\n",
            "35/35 [==============================] - 19s 535ms/step - loss: 0.0423 - val_loss: 0.0430\n",
            "Epoch 11/200\n",
            "35/35 [==============================] - 18s 526ms/step - loss: 0.0422 - val_loss: 0.0434\n",
            "Epoch 12/200\n",
            "35/35 [==============================] - 18s 527ms/step - loss: 0.0421 - val_loss: 0.0435\n",
            "Epoch 13/200\n",
            "35/35 [==============================] - 18s 522ms/step - loss: 0.0424 - val_loss: 0.0431\n",
            "Epoch 14/200\n",
            "35/35 [==============================] - 19s 538ms/step - loss: 0.0422 - val_loss: 0.0431\n",
            "Epoch 15/200\n",
            "35/35 [==============================] - 19s 531ms/step - loss: 0.0423 - val_loss: 0.0432\n",
            "Epoch 16/200\n",
            "35/35 [==============================] - 18s 528ms/step - loss: 0.0423 - val_loss: 0.0440\n",
            "Epoch 17/200\n",
            "35/35 [==============================] - 18s 524ms/step - loss: 0.0422 - val_loss: 0.0437\n",
            "Epoch 18/200\n",
            "35/35 [==============================] - 18s 527ms/step - loss: 0.0423 - val_loss: 0.0433\n",
            "Epoch 19/200\n",
            "35/35 [==============================] - 19s 537ms/step - loss: 0.0422 - val_loss: 0.0436\n",
            "Epoch 20/200\n",
            "35/35 [==============================] - 18s 522ms/step - loss: 0.0423 - val_loss: 0.0433\n",
            "Epoch 21/200\n",
            "35/35 [==============================] - 18s 522ms/step - loss: 0.0418 - val_loss: 0.0432\n",
            "Epoch 22/200\n",
            "35/35 [==============================] - 18s 519ms/step - loss: 0.0419 - val_loss: 0.0432\n",
            "Epoch 23/200\n",
            "35/35 [==============================] - 18s 520ms/step - loss: 0.0420 - val_loss: 0.0432\n",
            "Epoch 24/200\n",
            "35/35 [==============================] - 18s 523ms/step - loss: 0.0421 - val_loss: 0.0428\n",
            "Epoch 25/200\n",
            "35/35 [==============================] - 18s 524ms/step - loss: 0.0420 - val_loss: 0.0434\n",
            "Epoch 26/200\n",
            "35/35 [==============================] - 19s 530ms/step - loss: 0.0422 - val_loss: 0.0435\n",
            "Epoch 27/200\n",
            "35/35 [==============================] - 18s 523ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 28/200\n",
            "35/35 [==============================] - 18s 526ms/step - loss: 0.0422 - val_loss: 0.0436\n",
            "Epoch 29/200\n",
            "35/35 [==============================] - 18s 520ms/step - loss: 0.0420 - val_loss: 0.0431\n",
            "Epoch 30/200\n",
            "35/35 [==============================] - 19s 531ms/step - loss: 0.0422 - val_loss: 0.0431\n",
            "Epoch 31/200\n",
            "35/35 [==============================] - 19s 535ms/step - loss: 0.0422 - val_loss: 0.0431\n",
            "Epoch 32/200\n",
            "35/35 [==============================] - 18s 526ms/step - loss: 0.0421 - val_loss: 0.0427\n",
            "Epoch 33/200\n",
            "35/35 [==============================] - 19s 531ms/step - loss: 0.0421 - val_loss: 0.0432\n",
            "Epoch 34/200\n",
            "35/35 [==============================] - 18s 524ms/step - loss: 0.0425 - val_loss: 0.0432\n",
            "Epoch 35/200\n",
            "35/35 [==============================] - 19s 530ms/step - loss: 0.0420 - val_loss: 0.0429\n",
            "Epoch 36/200\n",
            "35/35 [==============================] - 18s 526ms/step - loss: 0.0421 - val_loss: 0.0427\n",
            "Epoch 37/200\n",
            "35/35 [==============================] - 18s 524ms/step - loss: 0.0421 - val_loss: 0.0431\n",
            "Epoch 38/200\n",
            "35/35 [==============================] - 19s 536ms/step - loss: 0.0419 - val_loss: 0.0432\n",
            "Epoch 39/200\n",
            "35/35 [==============================] - 18s 518ms/step - loss: 0.0420 - val_loss: 0.0435\n",
            "Epoch 40/200\n",
            "35/35 [==============================] - 18s 507ms/step - loss: 0.0420 - val_loss: 0.0433\n",
            "Epoch 41/200\n",
            "35/35 [==============================] - 18s 516ms/step - loss: 0.0424 - val_loss: 0.0430\n",
            "Epoch 42/200\n",
            "35/35 [==============================] - 18s 507ms/step - loss: 0.0421 - val_loss: 0.0430\n",
            "Epoch 43/200\n",
            "35/35 [==============================] - 18s 502ms/step - loss: 0.0422 - val_loss: 0.0433\n",
            "Epoch 44/200\n",
            "35/35 [==============================] - 18s 502ms/step - loss: 0.0419 - val_loss: 0.0431\n",
            "Epoch 45/200\n",
            "35/35 [==============================] - 17s 499ms/step - loss: 0.0420 - val_loss: 0.0432\n",
            "Epoch 46/200\n",
            "35/35 [==============================] - 17s 500ms/step - loss: 0.0422 - val_loss: 0.0430\n",
            "Epoch 47/200\n",
            "35/35 [==============================] - 18s 506ms/step - loss: 0.0420 - val_loss: 0.0432\n",
            "Epoch 48/200\n",
            "35/35 [==============================] - 17s 497ms/step - loss: 0.0421 - val_loss: 0.0431\n",
            "Epoch 49/200\n",
            "35/35 [==============================] - 17s 501ms/step - loss: 0.0422 - val_loss: 0.0429\n",
            "Epoch 50/200\n",
            "35/35 [==============================] - 18s 509ms/step - loss: 0.0418 - val_loss: 0.0430\n",
            "Epoch 51/200\n",
            "35/35 [==============================] - 18s 505ms/step - loss: 0.0419 - val_loss: 0.0431\n",
            "Epoch 52/200\n",
            "35/35 [==============================] - 18s 508ms/step - loss: 0.0420 - val_loss: 0.0436\n",
            "Epoch 53/200\n",
            "35/35 [==============================] - 18s 516ms/step - loss: 0.0420 - val_loss: 0.0432\n",
            "Epoch 54/200\n",
            "35/35 [==============================] - 18s 504ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 55/200\n",
            "35/35 [==============================] - 18s 509ms/step - loss: 0.0420 - val_loss: 0.0429\n",
            "Epoch 56/200\n",
            "35/35 [==============================] - 18s 506ms/step - loss: 0.0421 - val_loss: 0.0432\n",
            "Epoch 57/200\n",
            "35/35 [==============================] - 18s 506ms/step - loss: 0.0419 - val_loss: 0.0430\n",
            "Epoch 58/200\n",
            "35/35 [==============================] - 18s 505ms/step - loss: 0.0419 - val_loss: 0.0436\n",
            "Epoch 59/200\n",
            "35/35 [==============================] - 18s 502ms/step - loss: 0.0420 - val_loss: 0.0435\n",
            "Epoch 60/200\n",
            "35/35 [==============================] - 18s 504ms/step - loss: 0.0421 - val_loss: 0.0433\n",
            "Epoch 61/200\n",
            "35/35 [==============================] - 18s 515ms/step - loss: 0.0420 - val_loss: 0.0430\n",
            "Epoch 62/200\n",
            "35/35 [==============================] - 18s 506ms/step - loss: 0.0419 - val_loss: 0.0429\n",
            "Epoch 63/200\n",
            "35/35 [==============================] - 17s 496ms/step - loss: 0.0418 - val_loss: 0.0436\n",
            "Epoch 64/200\n",
            "35/35 [==============================] - 18s 515ms/step - loss: 0.0420 - val_loss: 0.0430\n",
            "Epoch 65/200\n",
            "35/35 [==============================] - 18s 503ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 66/200\n",
            "35/35 [==============================] - 18s 503ms/step - loss: 0.0420 - val_loss: 0.0427\n",
            "Epoch 67/200\n",
            "35/35 [==============================] - 18s 506ms/step - loss: 0.0421 - val_loss: 0.0431\n",
            "Epoch 68/200\n",
            "35/35 [==============================] - 17s 498ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 69/200\n",
            "35/35 [==============================] - 17s 499ms/step - loss: 0.0419 - val_loss: 0.0426\n",
            "Epoch 70/200\n",
            "35/35 [==============================] - 18s 512ms/step - loss: 0.0418 - val_loss: 0.0430\n",
            "Epoch 71/200\n",
            "35/35 [==============================] - 17s 498ms/step - loss: 0.0420 - val_loss: 0.0430\n",
            "Epoch 72/200\n",
            "35/35 [==============================] - 18s 505ms/step - loss: 0.0420 - val_loss: 0.0431\n",
            "Epoch 73/200\n",
            "35/35 [==============================] - 18s 502ms/step - loss: 0.0419 - val_loss: 0.0431\n",
            "Epoch 74/200\n",
            "35/35 [==============================] - 18s 507ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 75/200\n",
            "35/35 [==============================] - 18s 503ms/step - loss: 0.0422 - val_loss: 0.0431\n",
            "Epoch 76/200\n",
            "35/35 [==============================] - 18s 505ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 77/200\n",
            "35/35 [==============================] - 17s 496ms/step - loss: 0.0418 - val_loss: 0.0432\n",
            "Epoch 78/200\n",
            "35/35 [==============================] - 18s 506ms/step - loss: 0.0419 - val_loss: 0.0430\n",
            "Epoch 79/200\n",
            "35/35 [==============================] - 18s 504ms/step - loss: 0.0419 - val_loss: 0.0432\n",
            "Epoch 80/200\n",
            "35/35 [==============================] - 17s 501ms/step - loss: 0.0419 - val_loss: 0.0429\n",
            "Epoch 81/200\n",
            "35/35 [==============================] - 18s 514ms/step - loss: 0.0418 - val_loss: 0.0431\n",
            "Epoch 82/200\n",
            "35/35 [==============================] - 18s 514ms/step - loss: 0.0418 - val_loss: 0.0433\n",
            "Epoch 83/200\n",
            "35/35 [==============================] - 18s 509ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 84/200\n",
            "35/35 [==============================] - 18s 522ms/step - loss: 0.0420 - val_loss: 0.0431\n",
            "Epoch 85/200\n",
            "35/35 [==============================] - 18s 510ms/step - loss: 0.0420 - val_loss: 0.0432\n",
            "Epoch 86/200\n",
            "35/35 [==============================] - 18s 507ms/step - loss: 0.0420 - val_loss: 0.0429\n",
            "Epoch 87/200\n",
            "35/35 [==============================] - 18s 514ms/step - loss: 0.0420 - val_loss: 0.0429\n",
            "Epoch 88/200\n",
            "35/35 [==============================] - 17s 493ms/step - loss: 0.0420 - val_loss: 0.0428\n",
            "Epoch 89/200\n",
            "35/35 [==============================] - 17s 500ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 90/200\n",
            "35/35 [==============================] - 18s 506ms/step - loss: 0.0419 - val_loss: 0.0431\n",
            "Epoch 91/200\n",
            "35/35 [==============================] - 18s 506ms/step - loss: 0.0419 - val_loss: 0.0430\n",
            "Epoch 92/200\n",
            "35/35 [==============================] - 18s 516ms/step - loss: 0.0419 - val_loss: 0.0425\n",
            "Epoch 93/200\n",
            "35/35 [==============================] - 18s 511ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 94/200\n",
            "35/35 [==============================] - 18s 505ms/step - loss: 0.0417 - val_loss: 0.0429\n",
            "Epoch 95/200\n",
            "35/35 [==============================] - 18s 512ms/step - loss: 0.0418 - val_loss: 0.0430\n",
            "Epoch 96/200\n",
            "35/35 [==============================] - 18s 512ms/step - loss: 0.0419 - val_loss: 0.0430\n",
            "Epoch 97/200\n",
            "35/35 [==============================] - 18s 515ms/step - loss: 0.0418 - val_loss: 0.0432\n",
            "Epoch 98/200\n",
            "35/35 [==============================] - 18s 523ms/step - loss: 0.0419 - val_loss: 0.0429\n",
            "Epoch 99/200\n",
            "35/35 [==============================] - 18s 516ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 100/200\n",
            "35/35 [==============================] - 18s 518ms/step - loss: 0.0419 - val_loss: 0.0431\n",
            "Epoch 101/200\n",
            "35/35 [==============================] - 18s 519ms/step - loss: 0.0419 - val_loss: 0.0434\n",
            "Epoch 102/200\n",
            "35/35 [==============================] - 18s 507ms/step - loss: 0.0419 - val_loss: 0.0430\n",
            "Epoch 103/200\n",
            "35/35 [==============================] - 18s 513ms/step - loss: 0.0418 - val_loss: 0.0427\n",
            "Epoch 104/200\n",
            "35/35 [==============================] - 18s 514ms/step - loss: 0.0418 - val_loss: 0.0433\n",
            "Epoch 105/200\n",
            "35/35 [==============================] - 18s 503ms/step - loss: 0.0419 - val_loss: 0.0427\n",
            "Epoch 106/200\n",
            "35/35 [==============================] - 18s 508ms/step - loss: 0.0419 - val_loss: 0.0432\n",
            "Epoch 107/200\n",
            "35/35 [==============================] - 18s 506ms/step - loss: 0.0421 - val_loss: 0.0432\n",
            "Epoch 108/200\n",
            "35/35 [==============================] - 18s 509ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 109/200\n",
            "35/35 [==============================] - 18s 515ms/step - loss: 0.0419 - val_loss: 0.0430\n",
            "Epoch 110/200\n",
            "35/35 [==============================] - 17s 501ms/step - loss: 0.0417 - val_loss: 0.0428\n",
            "Epoch 111/200\n",
            "35/35 [==============================] - 18s 506ms/step - loss: 0.0419 - val_loss: 0.0431\n",
            "Epoch 112/200\n",
            "35/35 [==============================] - 18s 509ms/step - loss: 0.0419 - val_loss: 0.0431\n",
            "Epoch 113/200\n",
            "35/35 [==============================] - 18s 515ms/step - loss: 0.0418 - val_loss: 0.0427\n",
            "Epoch 114/200\n",
            "35/35 [==============================] - 18s 528ms/step - loss: 0.0417 - val_loss: 0.0427\n",
            "Epoch 115/200\n",
            "35/35 [==============================] - 18s 517ms/step - loss: 0.0418 - val_loss: 0.0431\n",
            "Epoch 116/200\n",
            "35/35 [==============================] - 18s 512ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 117/200\n",
            "35/35 [==============================] - 18s 507ms/step - loss: 0.0418 - val_loss: 0.0431\n",
            "Epoch 118/200\n",
            "35/35 [==============================] - 18s 507ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 119/200\n",
            "35/35 [==============================] - 18s 506ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 120/200\n",
            "35/35 [==============================] - 18s 515ms/step - loss: 0.0418 - val_loss: 0.0430\n",
            "Epoch 121/200\n",
            "35/35 [==============================] - 18s 512ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 122/200\n",
            "35/35 [==============================] - 18s 505ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 123/200\n",
            "35/35 [==============================] - 18s 508ms/step - loss: 0.0418 - val_loss: 0.0433\n",
            "Epoch 124/200\n",
            "35/35 [==============================] - 18s 508ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 125/200\n",
            "35/35 [==============================] - 18s 506ms/step - loss: 0.0420 - val_loss: 0.0430\n",
            "Epoch 126/200\n",
            "35/35 [==============================] - 18s 509ms/step - loss: 0.0419 - val_loss: 0.0431\n",
            "Epoch 127/200\n",
            "35/35 [==============================] - 18s 503ms/step - loss: 0.0420 - val_loss: 0.0430\n",
            "Epoch 128/200\n",
            "35/35 [==============================] - 18s 514ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 129/200\n",
            "35/35 [==============================] - 17s 499ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 130/200\n",
            "35/35 [==============================] - 17s 492ms/step - loss: 0.0419 - val_loss: 0.0429\n",
            "Epoch 131/200\n",
            "35/35 [==============================] - 18s 504ms/step - loss: 0.0419 - val_loss: 0.0429\n",
            "Epoch 132/200\n",
            "35/35 [==============================] - 17s 501ms/step - loss: 0.0419 - val_loss: 0.0430\n",
            "Epoch 133/200\n",
            "35/35 [==============================] - 18s 517ms/step - loss: 0.0418 - val_loss: 0.0431\n",
            "Epoch 134/200\n",
            "35/35 [==============================] - 18s 505ms/step - loss: 0.0418 - val_loss: 0.0432\n",
            "Epoch 135/200\n",
            "35/35 [==============================] - 18s 511ms/step - loss: 0.0419 - val_loss: 0.0429\n",
            "Epoch 136/200\n",
            "35/35 [==============================] - 18s 513ms/step - loss: 0.0419 - val_loss: 0.0429\n",
            "Epoch 137/200\n",
            "35/35 [==============================] - 18s 509ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 138/200\n",
            "35/35 [==============================] - 17s 501ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 139/200\n",
            "35/35 [==============================] - 18s 510ms/step - loss: 0.0418 - val_loss: 0.0431\n",
            "Epoch 140/200\n",
            "35/35 [==============================] - 18s 508ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 141/200\n",
            "35/35 [==============================] - 17s 498ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 142/200\n",
            "35/35 [==============================] - 18s 510ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 143/200\n",
            "35/35 [==============================] - 17s 499ms/step - loss: 0.0419 - val_loss: 0.0429\n",
            "Epoch 144/200\n",
            "35/35 [==============================] - 18s 514ms/step - loss: 0.0418 - val_loss: 0.0432\n",
            "Epoch 145/200\n",
            "35/35 [==============================] - 18s 509ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 146/200\n",
            "35/35 [==============================] - 18s 502ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 147/200\n",
            "35/35 [==============================] - 18s 505ms/step - loss: 0.0417 - val_loss: 0.0429\n",
            "Epoch 148/200\n",
            "35/35 [==============================] - 18s 509ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 149/200\n",
            "35/35 [==============================] - 18s 505ms/step - loss: 0.0419 - val_loss: 0.0430\n",
            "Epoch 150/200\n",
            "35/35 [==============================] - 18s 507ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 151/200\n",
            "35/35 [==============================] - 18s 511ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 152/200\n",
            "35/35 [==============================] - 18s 507ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 153/200\n",
            "35/35 [==============================] - 18s 517ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 154/200\n",
            "35/35 [==============================] - 18s 518ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 155/200\n",
            "35/35 [==============================] - 18s 515ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 156/200\n",
            "35/35 [==============================] - 18s 516ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 157/200\n",
            "35/35 [==============================] - 18s 514ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 158/200\n",
            "35/35 [==============================] - 18s 516ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 159/200\n",
            "35/35 [==============================] - 18s 514ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 160/200\n",
            "35/35 [==============================] - 18s 512ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 161/200\n",
            "35/35 [==============================] - 18s 524ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 162/200\n",
            "35/35 [==============================] - 18s 511ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 163/200\n",
            "35/35 [==============================] - 18s 522ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 164/200\n",
            "35/35 [==============================] - 18s 518ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 165/200\n",
            "35/35 [==============================] - 18s 506ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 166/200\n",
            "35/35 [==============================] - 18s 518ms/step - loss: 0.0418 - val_loss: 0.0430\n",
            "Epoch 167/200\n",
            "35/35 [==============================] - 18s 508ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 168/200\n",
            "35/35 [==============================] - 18s 516ms/step - loss: 0.0418 - val_loss: 0.0430\n",
            "Epoch 169/200\n",
            "35/35 [==============================] - 18s 517ms/step - loss: 0.0418 - val_loss: 0.0427\n",
            "Epoch 170/200\n",
            "35/35 [==============================] - 18s 513ms/step - loss: 0.0418 - val_loss: 0.0432\n",
            "Epoch 171/200\n",
            "35/35 [==============================] - 18s 510ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 172/200\n",
            "35/35 [==============================] - 18s 510ms/step - loss: 0.0417 - val_loss: 0.0429\n",
            "Epoch 173/200\n",
            "35/35 [==============================] - 18s 507ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 174/200\n",
            "35/35 [==============================] - 18s 527ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 175/200\n",
            "35/35 [==============================] - 18s 511ms/step - loss: 0.0418 - val_loss: 0.0431\n",
            "Epoch 176/200\n",
            "35/35 [==============================] - 17s 501ms/step - loss: 0.0418 - val_loss: 0.0430\n",
            "Epoch 177/200\n",
            "35/35 [==============================] - 18s 508ms/step - loss: 0.0418 - val_loss: 0.0431\n",
            "Epoch 178/200\n",
            "35/35 [==============================] - 17s 500ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 179/200\n",
            "35/35 [==============================] - 18s 506ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 180/200\n",
            "35/35 [==============================] - 18s 510ms/step - loss: 0.0418 - val_loss: 0.0430\n",
            "Epoch 181/200\n",
            "35/35 [==============================] - 18s 510ms/step - loss: 0.0417 - val_loss: 0.0428\n",
            "Epoch 182/200\n",
            "35/35 [==============================] - 18s 508ms/step - loss: 0.0418 - val_loss: 0.0430\n",
            "Epoch 183/200\n",
            "35/35 [==============================] - 18s 508ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 184/200\n",
            "35/35 [==============================] - 18s 517ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 185/200\n",
            "35/35 [==============================] - 18s 524ms/step - loss: 0.0419 - val_loss: 0.0428\n",
            "Epoch 186/200\n",
            "35/35 [==============================] - 18s 506ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 187/200\n",
            "35/35 [==============================] - 18s 509ms/step - loss: 0.0418 - val_loss: 0.0430\n",
            "Epoch 188/200\n",
            "35/35 [==============================] - 18s 510ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 189/200\n",
            "35/35 [==============================] - 18s 502ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 190/200\n",
            "35/35 [==============================] - 18s 510ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 191/200\n",
            "35/35 [==============================] - 18s 504ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 192/200\n",
            "35/35 [==============================] - 18s 510ms/step - loss: 0.0418 - val_loss: 0.0430\n",
            "Epoch 193/200\n",
            "35/35 [==============================] - 18s 519ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 194/200\n",
            "35/35 [==============================] - 18s 519ms/step - loss: 0.0418 - val_loss: 0.0431\n",
            "Epoch 195/200\n",
            "35/35 [==============================] - 18s 510ms/step - loss: 0.0418 - val_loss: 0.0430\n",
            "Epoch 196/200\n",
            "35/35 [==============================] - 18s 507ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 197/200\n",
            "35/35 [==============================] - 18s 508ms/step - loss: 0.0418 - val_loss: 0.0428\n",
            "Epoch 198/200\n",
            "35/35 [==============================] - 18s 508ms/step - loss: 0.0418 - val_loss: 0.0429\n",
            "Epoch 199/200\n",
            "35/35 [==============================] - 18s 510ms/step - loss: 0.0419 - val_loss: 0.0429\n",
            "Epoch 200/200\n",
            "35/35 [==============================] - 18s 515ms/step - loss: 0.0417 - val_loss: 0.0428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Evaluation\n"
      ],
      "metadata": {
        "id": "_Xh3f6alR4nc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.image import psnr as tf_psnr, ssim as tf_ssim\n",
        "from tensorflow.image import resize\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "CHANNELS = 3\n",
        "\n",
        "RAW_TEST_PATH = '/content/Test/Raw'\n",
        "REFERENCE_TEST_PATH = '/content/Test/Reference'\n",
        "\n",
        "def load_images_from_folder(folder, img_width=224, img_height=224):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = load_img(img_path, target_size=(img_height, img_width))\n",
        "        img_array = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
        "        images.append(img_array)\n",
        "    return np.array(images)\n",
        "\n",
        "# Now, reload the images with the updated function\n",
        "raw_test_images = load_images_from_folder(RAW_TEST_PATH)\n",
        "reference_test_images = load_images_from_folder(REFERENCE_TEST_PATH)\n",
        "\n",
        "predicted_images = vae_model.predict(raw_test_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCF48zUXPB67",
        "outputId": "343dd08f-80d5-4ca7-841d-6407bbe8eb39"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.67.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "6/6 [==============================] - 2s 371ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_images[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6wFEPcvUjqL",
        "outputId": "a2606a0b-7aa7-49f3-bea6-ff7651dbdee5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference_test_images[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL49dimOUmNc",
        "outputId": "994a9cd6-3768-461d-a5ca-b043da27ef76"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "source": [
        "# Define MSE, PSNR, and SSIM functions\n",
        "def mse(y_true, y_pred):\n",
        "    return np.mean(np.square(y_true - y_pred))\n",
        "\n",
        "def psnr(y_true, y_pred):\n",
        "    max_pixel = 1.0\n",
        "    return 20 * np.log10(max_pixel / np.sqrt(mse(y_true, y_pred)))\n",
        "\n",
        "def ssim(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf_ssim(y_true, y_pred, max_val=1.0))\n",
        "\n",
        "mse_values = []\n",
        "psnr_values = []\n",
        "ssim_values = []\n",
        "\n",
        "for i in range(len(predicted_images)):\n",
        "    mse_val = mse(reference_test_images[i], predicted_images[i])\n",
        "    psnr_val = psnr(reference_test_images[i], predicted_images[i])\n",
        "    ssim_val = ssim(reference_test_images[i], predicted_images[i])\n",
        "\n",
        "    mse_values.append(mse_val)\n",
        "    psnr_values.append(psnr_val)\n",
        "    ssim_values.append(ssim_val)\n",
        "\n",
        "# Calculate the mean of the evaluation metrics over the test set\n",
        "mean_mse = np.mean(mse_values)\n",
        "mean_psnr = np.mean(psnr_values)\n",
        "mean_ssim = np.mean(ssim_values)\n",
        "\n",
        "print(f\"Mean MSE: {mean_mse}\")\n",
        "print(f\"Mean PSNR: {mean_psnr}\")\n",
        "print(f\"Mean SSIM: {mean_ssim}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqyP44AXmKF4",
        "outputId": "85a0b2c4-5d8c-4cdb-9212-8fb947cef976"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MSE: 0.08615907281637192\n",
            "Mean PSNR: 10.881352121899013\n",
            "Mean SSIM: 0.23851041495800018\n"
          ]
        }
      ]
    }
  ]
}