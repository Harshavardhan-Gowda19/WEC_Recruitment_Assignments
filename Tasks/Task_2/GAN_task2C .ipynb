{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgdX-0V6xg7K",
        "outputId": "ec8803d9-6168-48f8-909e-9af676079662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/archive.zip\" /content/"
      ],
      "metadata": {
        "id": "pyLJsk5wxxiT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/archive.zip\" -d /content/"
      ],
      "metadata": {
        "id": "zVw3S0rCx5pC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "qH6tbodM9Cvb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset Class\n",
        "class UnderwaterImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.raw_images = sorted(os.listdir(os.path.join(root_dir, '/content/Train/Raw')))\n",
        "        self.reference_images = sorted(os.listdir(os.path.join(root_dir, '/content/Train/Reference')))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.raw_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        raw_image_path = os.path.join(self.root_dir, '/content/Train/Raw', self.raw_images[idx])\n",
        "        reference_image_path = os.path.join(self.root_dir, '/content/Train/Reference', self.reference_images[idx])\n",
        "\n",
        "        raw_image = Image.open(raw_image_path).convert(\"RGB\")\n",
        "        reference_image = Image.open(reference_image_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            raw_image = self.transform(raw_image)\n",
        "            reference_image = self.transform(reference_image)\n",
        "\n",
        "        return raw_image, reference_image\n"
      ],
      "metadata": {
        "id": "aSaWpch09FvG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "])\n",
        "\n",
        "dataset = UnderwaterImageDataset(root_dir='Dataset', transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "GQxAho7g9STj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNet Generator\n",
        "class UNetGenerator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNetGenerator, self).__init__()\n",
        "        self.encoder1 = nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1)  # Downsample\n",
        "        self.encoder2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
        "        self.decoder1 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)  # Upsample\n",
        "        self.decoder2 = nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = F.leaky_relu(self.encoder1(x))\n",
        "        enc2 = F.leaky_relu(self.encoder2(enc1))\n",
        "        dec1 = F.relu(self.decoder1(enc2))\n",
        "        dec2 = self.decoder2(dec1)\n",
        "        return dec2\n",
        "\n",
        "class PatchDiscriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PatchDiscriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(6, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 1, kernel_size=4, stride=1, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "vAJb0rrA9WQG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# L1 Loss Function\n",
        "def l1_loss(y_true, y_pred):\n",
        "    return F.l1_loss(y_true, y_pred)"
      ],
      "metadata": {
        "id": "rtyVsBKH9ZHM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "lambda_l1 = 100\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 50\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "generator = UNetGenerator().to(device)\n",
        "discriminator = PatchDiscriminator().to(device)"
      ],
      "metadata": {
        "id": "Rqvhw8OO9blB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (real_images, target_images) in enumerate(dataloader):\n",
        "        real_images = real_images.to(device)\n",
        "        target_images = target_images.to(device)\n",
        "\n",
        "        # Train Discriminator\n",
        "        optimizer_D.zero_grad()\n",
        "        fake_images = generator(real_images)\n",
        "\n",
        "        real_pairs = torch.cat((real_images, target_images), dim=1)\n",
        "        fake_pairs = torch.cat((real_images, fake_images.detach()), dim=1)\n",
        "\n",
        "        D_real = discriminator(real_pairs)\n",
        "        D_fake = discriminator(fake_pairs)\n",
        "\n",
        "        # Clamping outputs\n",
        "        eps = 1e-8  # A small value to avoid log(0)\n",
        "        loss_D = -torch.mean(torch.log(D_real + eps) + torch.log(1 - D_fake + eps))\n",
        "        loss_D.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "\n",
        "        # Train Generator\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Computation of G loss\n",
        "        D_fake_for_G = discriminator(fake_pairs)\n",
        "        loss_G_GAN = -torch.mean(torch.log(D_fake_for_G))\n",
        "        loss_G_L1 = l1_loss(target_images, fake_images)\n",
        "        loss_G = loss_G_GAN + lambda_l1 * loss_G_L1\n",
        "\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    print(f'Epoch [{epoch}/{num_epochs}], Loss D: {loss_D.item()}, Loss G: {loss_G.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_CSpu9l9ise",
        "outputId": "f9e6180b-da1c-4c9f-fa4a-cb36a8c45bfc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/50], Loss D: 0.570707380771637, Loss G: 17.290164947509766\n",
            "Epoch [1/50], Loss D: 0.7995550036430359, Loss G: 22.42626953125\n",
            "Epoch [2/50], Loss D: 0.6717220544815063, Loss G: 20.798009872436523\n",
            "Epoch [3/50], Loss D: 0.6300781965255737, Loss G: 20.150964736938477\n",
            "Epoch [4/50], Loss D: 0.21730884909629822, Loss G: 29.954578399658203\n",
            "Epoch [5/50], Loss D: 0.1986531764268875, Loss G: 24.817581176757812\n",
            "Epoch [6/50], Loss D: 0.29798245429992676, Loss G: 20.87131690979004\n",
            "Epoch [7/50], Loss D: 0.2675427496433258, Loss G: 23.649805068969727\n",
            "Epoch [8/50], Loss D: 0.2299765944480896, Loss G: 21.938749313354492\n",
            "Epoch [9/50], Loss D: 0.34901124238967896, Loss G: 19.72670555114746\n",
            "Epoch [10/50], Loss D: 1.1516358852386475, Loss G: 13.272932052612305\n",
            "Epoch [11/50], Loss D: 0.9599515199661255, Loss G: 16.538795471191406\n",
            "Epoch [12/50], Loss D: 0.15175946056842804, Loss G: 30.893850326538086\n",
            "Epoch [13/50], Loss D: 0.25608018040657043, Loss G: 29.184165954589844\n",
            "Epoch [14/50], Loss D: 0.566315233707428, Loss G: 13.652629852294922\n",
            "Epoch [15/50], Loss D: 0.5661653876304626, Loss G: 21.93650245666504\n",
            "Epoch [16/50], Loss D: 0.4196912944316864, Loss G: 21.97755241394043\n",
            "Epoch [17/50], Loss D: 1.453075885772705, Loss G: 14.66193675994873\n",
            "Epoch [18/50], Loss D: 0.8761347532272339, Loss G: 13.058426856994629\n",
            "Epoch [19/50], Loss D: 0.04393303021788597, Loss G: 29.0484676361084\n",
            "Epoch [20/50], Loss D: 0.40480080246925354, Loss G: 17.193944931030273\n",
            "Epoch [21/50], Loss D: 0.3524191975593567, Loss G: 24.619312286376953\n",
            "Epoch [22/50], Loss D: 0.41340550780296326, Loss G: 18.640737533569336\n",
            "Epoch [23/50], Loss D: 0.37189486622810364, Loss G: 21.420623779296875\n",
            "Epoch [24/50], Loss D: 0.3648746609687805, Loss G: 37.00086212158203\n",
            "Epoch [25/50], Loss D: 0.3330886960029602, Loss G: 19.436904907226562\n",
            "Epoch [26/50], Loss D: 1.4555976390838623, Loss G: 16.28942108154297\n",
            "Epoch [27/50], Loss D: 0.11213546246290207, Loss G: 27.136226654052734\n",
            "Epoch [28/50], Loss D: 1.3943052291870117, Loss G: 12.093174934387207\n",
            "Epoch [29/50], Loss D: 0.6615744233131409, Loss G: 17.137237548828125\n",
            "Epoch [30/50], Loss D: 0.7888391613960266, Loss G: 16.950183868408203\n",
            "Epoch [31/50], Loss D: 0.4193195700645447, Loss G: 25.408737182617188\n",
            "Epoch [32/50], Loss D: 0.568234920501709, Loss G: 18.261030197143555\n",
            "Epoch [33/50], Loss D: 0.40599387884140015, Loss G: 18.14126205444336\n",
            "Epoch [34/50], Loss D: 0.19547893106937408, Loss G: 25.65875816345215\n",
            "Epoch [35/50], Loss D: 0.4893326461315155, Loss G: 24.4101505279541\n",
            "Epoch [36/50], Loss D: 0.1868361085653305, Loss G: 18.864120483398438\n",
            "Epoch [37/50], Loss D: 0.37355703115463257, Loss G: 20.10700035095215\n",
            "Epoch [38/50], Loss D: 0.31575480103492737, Loss G: 13.293672561645508\n",
            "Epoch [39/50], Loss D: 0.8821872472763062, Loss G: 12.160506248474121\n",
            "Epoch [40/50], Loss D: 1.124082326889038, Loss G: 14.109374046325684\n",
            "Epoch [41/50], Loss D: 0.2117050737142563, Loss G: 22.456390380859375\n",
            "Epoch [42/50], Loss D: 0.46317997574806213, Loss G: 14.660982131958008\n",
            "Epoch [43/50], Loss D: 0.47856107354164124, Loss G: 12.761580467224121\n",
            "Epoch [44/50], Loss D: 0.25634562969207764, Loss G: 13.098013877868652\n",
            "Epoch [45/50], Loss D: 2.098252534866333, Loss G: 12.22528076171875\n",
            "Epoch [46/50], Loss D: 0.12695159018039703, Loss G: 20.870702743530273\n",
            "Epoch [47/50], Loss D: 0.2648327946662903, Loss G: 30.235071182250977\n",
            "Epoch [48/50], Loss D: 0.06022235006093979, Loss G: 52.494407653808594\n",
            "Epoch [49/50], Loss D: 0.46747124195098877, Loss G: 15.577576637268066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# MSE Calculation\n",
        "def mse(image1, image2):\n",
        "    return F.mse_loss(image1, image2)\n",
        "\n",
        "# PSNR Calculation\n",
        "def psnr(image1, image2, max_val=1.0):\n",
        "    mse_value = mse(image1, image2)\n",
        "    psnr_value = 10 * torch.log10(max_val ** 2 / mse_value)\n",
        "    return psnr_value\n",
        "\n",
        "# SSIM Calculation\n",
        "def ssim(image1, image2, C1=0.01**2, C2=0.03**2):\n",
        "    mu1 = F.avg_pool2d(image1, kernel_size=11, stride=1, padding=5)\n",
        "    mu2 = F.avg_pool2d(image2, kernel_size=11, stride=1, padding=5)\n",
        "\n",
        "    mu1_sq = mu1 ** 2\n",
        "    mu2_sq = mu2 ** 2\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "\n",
        "    sigma1_sq = F.avg_pool2d(image1 ** 2, kernel_size=11, stride=1, padding=5) - mu1_sq\n",
        "    sigma2_sq = F.avg_pool2d(image2 ** 2, kernel_size=11, stride=1, padding=5) - mu2_sq\n",
        "    sigma12 = F.avg_pool2d(image1 * image2, kernel_size=11, stride=1, padding=5) - mu1_mu2\n",
        "\n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
        "    return ssim_map.mean()\n"
      ],
      "metadata": {
        "id": "gMPSqQWC9pX3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define the custom dataset\n",
        "class PairedImageDataset(Dataset):\n",
        "    def __init__(self, raw_dir, reference_dir, transform=None):\n",
        "        self.raw_dir = raw_dir\n",
        "        self.reference_dir = reference_dir\n",
        "        self.transform = transform\n",
        "        self.image_filenames = os.listdir(raw_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_filename = self.image_filenames[idx]\n",
        "        raw_image_path = os.path.join(self.raw_dir, image_filename)\n",
        "        reference_image_path = os.path.join(self.reference_dir, image_filename)\n",
        "\n",
        "        raw_image = Image.open(raw_image_path).convert('RGB')\n",
        "        reference_image = Image.open(reference_image_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            raw_image = self.transform(raw_image)\n",
        "            reference_image = self.transform(reference_image)\n",
        "\n",
        "        return raw_image, reference_image\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "raw_dir = '/content/Test/Raw'\n",
        "reference_dir = '/content/Test/Reference'\n",
        "test_dataset = PairedImageDataset(raw_dir, reference_dir, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "import torch\n",
        "\n",
        "# Set the generator to evaluation mode\n",
        "generator.eval()\n",
        "\n",
        "# Initialize accumulators for MSE, PSNR, SSIM\n",
        "mse_total = 0.0\n",
        "psnr_total = 0.0\n",
        "ssim_total = 0.0\n",
        "num_samples = len(test_loader)\n",
        "\n",
        "for raw_image, reference_image in test_loader:\n",
        "    with torch.no_grad():\n",
        "        generated_image = generator(raw_image)\n",
        "\n",
        "    generated_image = (generated_image + 1) / 2\n",
        "    reference_image = (reference_image + 1) / 2\n",
        "\n",
        "    mse_value = mse(generated_image, reference_image)\n",
        "    psnr_value = psnr(generated_image, reference_image)\n",
        "    ssim_value = ssim(generated_image, reference_image)\n",
        "\n",
        "    mse_total += mse_value.item()\n",
        "    psnr_total += psnr_value.item()\n",
        "    ssim_total += ssim_value.item()\n",
        "\n",
        "mean_mse = mse_total / num_samples\n",
        "mean_psnr = psnr_total / num_samples\n",
        "mean_ssim = ssim_total / num_samples\n",
        "\n",
        "print(f\"Mean MSE: {mean_mse}\")\n",
        "print(f\"Mean PSNR: {mean_psnr}\")\n",
        "print(f\"Mean SSIM: {mean_ssim}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBwNmG7c9y3p",
        "outputId": "3ea70506-2c93-4b6c-b140-baa38419ddd7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MSE: 0.01947583749057039\n",
            "Mean PSNR: 18.910640776784795\n",
            "Mean SSIM: 0.8239411484254034\n"
          ]
        }
      ]
    }
  ]
}